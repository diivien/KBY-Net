{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-21T00:54:13.909114Z","iopub.status.busy":"2024-06-21T00:54:13.908385Z","iopub.status.idle":"2024-06-21T00:54:28.315032Z","shell.execute_reply":"2024-06-21T00:54:28.313823Z","shell.execute_reply.started":"2024-06-21T00:54:13.909077Z"},"id":"_CphAn8Xeu5W","outputId":"22158af2-ba0c-4125-8b22-5a8a1bd0a135","papermill":{"duration":14.97648,"end_time":"2024-02-25T14:26:28.639811","exception":false,"start_time":"2024-02-25T14:26:13.663331","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["!pip install einops\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-21T00:54:28.318118Z","iopub.status.busy":"2024-06-21T00:54:28.317746Z","iopub.status.idle":"2024-06-21T00:54:31.974847Z","shell.execute_reply":"2024-06-21T00:54:31.973711Z","shell.execute_reply.started":"2024-06-21T00:54:28.318082Z"},"id":"gF5QzVzwTEF2","papermill":{"duration":7.108776,"end_time":"2024-02-25T14:26:50.185797","exception":false,"start_time":"2024-02-25T14:26:43.077021","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["\n","import os\n","import torch\n","import torch.nn.functional as F\n","import copy\n","import random\n","import numpy as np\n","import math\n","import csv\n","import warnings\n","import tqdm\n","from torch.utils.data import DataLoader\n","from model.kbynet import YOLO\n","from model.metrics import EMA, AverageMeter, ComputeLoss, psnr,ssim\n","from model.dataset import YOLODataset, collateFunction\n","from model.utils import clip_gradients,strip_optimizer,scale,box_iou,compute_ap,non_max_suppression\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-21T00:54:32.195044Z","iopub.status.busy":"2024-06-21T00:54:32.194686Z","iopub.status.idle":"2024-06-21T00:54:32.295643Z","shell.execute_reply":"2024-06-21T00:54:32.294746Z","shell.execute_reply.started":"2024-06-21T00:54:32.195016Z"},"id":"ltEYkp34TPns","papermill":{"duration":0.100489,"end_time":"2024-02-25T14:26:50.57853","exception":false,"start_time":"2024-02-25T14:26:50.478041","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["\n","\n","def setup_seed():\n","    \"\"\"\n","    Setup random seed.\n","    \"\"\"\n","    random.seed(0)\n","    np.random.seed(0)\n","    torch.manual_seed(0)\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","\n","\n","def setup_multi_processes():\n","    \"\"\"\n","    Setup multi-processing environment variables.\n","    \"\"\"\n","    import cv2\n","    from os import environ\n","    from platform import system\n","\n","    # set multiprocess start method as `fork` to speed up the training\n","    if system() != 'Windows':\n","        torch.multiprocessing.set_start_method('fork', force=True)\n","\n","    # disable opencv multithreading to avoid system being overloaded\n","    cv2.setNumThreads(0)\n","\n","    # setup OMP threads\n","    if 'OMP_NUM_THREADS' not in environ:\n","        environ['OMP_NUM_THREADS'] = '1'\n","\n","    # setup MKL threads\n","    if 'MKL_NUM_THREADS' not in environ:\n","        environ['MKL_NUM_THREADS'] = '1'\n","\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-21T00:54:32.475686Z","iopub.status.busy":"2024-06-21T00:54:32.475298Z","iopub.status.idle":"2024-06-21T00:54:32.728293Z","shell.execute_reply":"2024-06-21T00:54:32.727416Z","shell.execute_reply.started":"2024-06-21T00:54:32.475651Z"},"id":"PVcPpKj1TUP4","papermill":{"duration":0.139717,"end_time":"2024-02-25T14:26:52.038924","exception":false,"start_time":"2024-02-25T14:26:51.899207","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","def custom_exponential_lr(gamma):\n","    return lambda epoch:  gamma ** epoch\n","\n","def one_cycle(y1=0.0, y2=1.0, steps=100):\n","    \"\"\"Returns a lambda function for sinusoidal ramp from y1 to y2 https://arxiv.org/pdf/1812.01187.pdf.\"\"\"\n","    return lambda x: max((1 - math.cos(x * math.pi / steps)) / 2, 0) * (y2 - y1) + y1\n","\n","def learning_rate(args):\n","    def fn(x):\n","        return (1 - x / args['epochs']) * (1.0 - args['lrf']) + args['lrf']\n","\n","    return fn\n","\n","\n","def train(args):\n","    # Model\n","    checkpoint_path = '/kaggle/input/vocfogalst/none.pt'\n","    optimizer_state_dict = None\n","    amp_scale_state_dict = None\n","    start_epoch = 0\n","    best = 0\n","    ema_state_dict = None\n","    scheduler_state_dict = None\n","    depth = [1, 2, 2]\n","    width = [3, 32, 64, 128, 256, 512]\n","    model = YOLO(width, depth, args['nc']).cuda()\n","    weight_opt = None\n","    if os.path.exists(checkpoint_path):\n","        ckpt = torch.load(checkpoint_path)\n","        model_state_dict = ckpt['model'].state_dict()\n","        model.load_state_dict(model_state_dict)\n","        optimizer_state_dict = ckpt['optimizer']\n","        amp_scale_state_dict = ckpt['amp_scale']\n","        start_epoch = ckpt['epoch'] + 1\n","        best = ckpt['best']\n","        ema_state_dict = ckpt['ema'].state_dict()\n","        ema_updates = ckpt['ema_updates']\n","        scheduler_state_dict = ckpt['scheduler']\n","#         weight_opt = ckpt['weight_opt']\n","        print(f'Resuming training from epoch {start_epoch}')\n","    else:\n","        # Load the entire state dict\n","        # Filter out keys that contain 'head'\n","        device          = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        model_dict      = model.state_dict()\n","        pretrained_dict = torch.load(\"/kaggle/input/utilis2/yolov8_s.pt\", map_location = device)\n","        items = list(pretrained_dict.items())\n","        pretrained_dict = {k: v for k, v in pretrained_dict.items() if np.shape(model_dict[k]) == np.shape(v)}\n","        model_dict.update(pretrained_dict)\n","        model.load_state_dict(model_dict)\n","\n","    ema = EMA(model)\n","    if ema_state_dict is not None:\n","        print('Load ema')\n","        ema.ema.load_state_dict(ema_state_dict)\n","        ema.updates = ema_updates\n","\n","    accumulate = max(round(64 / (args['batch_size'] )), 1)\n","    args['weight_decay'] *= args['batch_size']  * accumulate / 64\n","    print(args['weight_decay'])\n","    model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n","    model = torch.nn.DataParallel(model)\n","\n","    UnFreeze_flag = False\n","\n","    param_names = [name for name, param in model.named_parameters() if param.requires_grad]\n","    layers_to_freeze = param_names[:69]\n","    if args['Freeze_Train']:\n","        print('Freezing Layer...')\n","        for k, v in model.named_parameters():\n","            if k in layers_to_freeze:\n","                v.requires_grad = False\n","                print(k)\n","\n","\n","    def get_param_group(i, k):\n","        if i <= 98:  # backbone layers\n","            return 'backbone'\n","        elif 99 <= i <= 374:  # specific layers\n","            return 'res'\n","        else:\n","            return 'det'\n","\n","    # Define dictionaries to hold parameters of different layers and types\n","    params = {'backbone': {'bias': [], 'norm': [], 'others': []},\n","              'res': {'bias': [], 'norm': [], 'others': []},\n","              'det': {'bias': [], 'norm': [], 'others': []}}\n","\n","#     # Loop over named parameters\n","    for i, (k, v) in enumerate(model.named_parameters()):\n","        group = get_param_group(i, k)\n","        if 'bias' in k or 'b_custom' in k:\n","            params[group]['bias'].append(v)\n","            param_type = 'bias'\n","        elif 'norm' in k:\n","            params[group]['norm'].append(v)\n","            param_type = 'norm'\n","        else:\n","            params[group]['others'].append(v)\n","            param_type = 'others'\n","        print(f\"Layer {i}: {k}, Group: {group}, Type: {param_type}\")  # print layer name, group, and type\n","\n","\n","\n","\n","    optimizer = torch.optim.SGD(params['backbone']['bias'], lr=args['lr0'], momentum=args['momentum'], weight_decay=0)\n","\n","    optimizer.add_param_group({'params': params['backbone']['norm'], 'lr': args['lr0'],'weight_decay': 0})\n","    optimizer.add_param_group({'params': params['backbone']['others'], 'lr': args['lr0'], 'weight_decay': args['weight_decay']})\n","    optimizer.add_param_group({'params': params['res']['bias'], 'lr': args['lr1'], 'weight_decay': 0})\n","    optimizer.add_param_group({'params': params['res']['norm'], 'lr': args['lr1'],'weight_decay': 0})\n","    optimizer.add_param_group({'params': params['res']['others'],'lr': args['lr1'], 'weight_decay': args['weight_decay']})\n","    optimizer.add_param_group({'params': params['det']['bias'], 'lr': args['lr2'], 'weight_decay': 0})\n","    optimizer.add_param_group({'params': params['det']['norm'],'lr': args['lr2'], 'weight_decay': 0})\n","    optimizer.add_param_group({'params': params['det']['others'], 'lr': args['lr2'], 'weight_decay': args['weight_decay']})\n","\n","\n","    if optimizer_state_dict is not None:\n","        print('Load optimizier')\n","        optimizer.load_state_dict(optimizer_state_dict)\n","\n","    del params\n","\n","    lr0 = one_cycle(1, args['lrf'], args['cosine_epochs'])\n","    lr1 = one_cycle(1, args['lrf'], args['cosine_epochs'])\n","    lr2 = one_cycle(1, args['lrf'], args['cosine_epochs'])\n","\n","    train_dir = '/kaggle/input/vocfog/vocfog/train'\n","\n","\n","    dataset = YOLODataset(train_dir, args['input_size'], args, True)\n","    loader = DataLoader(dataset, batch_size=args['batch_size'], num_workers=4,\n","                                   shuffle=True,collate_fn=collateFunction)\n","    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=[lr0]*3+[lr1]*3+[lr2]*3, last_epoch=start_epoch-1)\n","\n","\n","    if scheduler_state_dict is not None:\n","        print('Load scheduler')\n","        scheduler.load_state_dict(scheduler_state_dict)\n","        print(scheduler_state_dict)\n","\n","\n","    # Start training\n","    num_batch = len(loader)\n","    amp_scale = torch.cuda.amp.GradScaler()\n","    if amp_scale_state_dict is not None:\n","        print('Load scaler')\n","\n","        amp_scale.load_state_dict(amp_scale_state_dict)\n","\n","    criterion = ComputeLoss(model, args)\n","\n","\n","\n","    num_warmup = max(round(args['warmup_epochs'] * num_batch), 1000)\n","\n","    with open('step.csv', 'w') as f:\n","        writer = csv.DictWriter(f, fieldnames=['epoch', 'mAP@50', 'mAP','PSNR','SSIM', 'total_loss','det_loss','res_loss','val_loss','val_det','val_res'])\n","        writer.writeheader()\n","        for epoch in range(start_epoch, args['epochs']):\n","            model.train()\n","            if epoch >= args['Freeze_Epoch'] and not UnFreeze_flag and args['Freeze_Train']:\n","                print('unfreeze')\n","\n","                for k, v in model.named_parameters():\n","                    if  k in layers_to_freeze:\n","                        v.requires_grad = True\n","\n","\n","                UnFreeze_flag = True\n","            m_loss = AverageMeter()\n","            r_loss = AverageMeter()\n","            d_loss = AverageMeter()\n","            p_bar = enumerate(loader)\n","            print(('\\n' + '%10s' * 3) % ('epoch', 'memory', 'loss'))\n","            p_bar = tqdm.tqdm(p_bar, total=num_batch)  # progress bar\n","\n","            optimizer.zero_grad()\n","\n","            for i, (samples,norain, targets,shapes) in p_bar:\n","                x = i + num_batch * epoch  # number of iterations\n","                samples = samples.float()\n","                norain = norain.float()\n","                samples = samples.cuda()\n","                norain = norain.cuda()\n","                targets = targets.cuda()\n","\n","                pad_w, pad_h = shapes[0][1][1]\n","                pad_w, pad_h = int(pad_w), int(pad_h)\n","                _, _, height, width = samples.shape\n","\n","                if x <= num_warmup:\n","                    xp = [0, num_warmup]\n","                    fp = [1, 64 / (args['batch_size'] * args['world_size'])]\n","                    accumulate = max(1, np.interp(x, xp, fp).round())\n","                    for j, y in enumerate(optimizer.param_groups):\n","                        if j == 0 or j == 3 or j == 6:\n","                            fp = [args['warmup_bias_lr'], y['initial_lr'] * lr1(epoch)]\n","                        else:\n","                            fp = [0.0, y['initial_lr'] * lr1(epoch)]\n","                        y['lr'] = np.interp(x, xp, fp)\n","                        if 'momentum' in y:\n","                            fp = [args['warmup_momentum'], args['momentum']]\n","                            y['momentum'] = np.interp(x, xp, fp)\n","\n","\n","                # Forward\n","                with torch.cuda.amp.autocast(enabled=True ):\n","                    outputs = model(samples)  # forward\n","                    det_loss = criterion(outputs['Detection'], targets)\n","                    res_loss = F.l1_loss(outputs['Restoration'], norain)\n","\n","\n","                    loss = (args['det']*det_loss) + (args['res']*res_loss) \n","\n","\n","                m_loss.update(loss.item(), samples.size(0))\n","                d_loss.update(det_loss.item(), samples.size(0))\n","                r_loss.update(res_loss.item(), samples.size(0))\n","\n","\n","\n","                amp_scale.scale(loss).backward()\n","\n","                \n","                if x % accumulate == 0:\n","                    amp_scale.unscale_(optimizer)  # unscale gradients\n","                    clip_gradients(model)  # clip gradients\n","                    amp_scale.step(optimizer)  # optimizer.step\n","                    amp_scale.update()\n","                    optimizer.zero_grad()\n","                    if ema:\n","                        ema.update(model)\n","\n","\n","\n","                memory = f'{torch.cuda.memory_reserved() / 1E9:.3g}G'  # (GB)\n","                s = ('%10s' * 2 + '%10.4g' + '%10.4g' + '%10.4g' +'%10.4g' ) % (f\"{epoch + 1}/{args['epochs']}\", memory, m_loss.avg, d_loss.avg, r_loss.avg,\n","                                                                               scheduler.optimizer.param_groups[0]['lr'])\n","                p_bar.set_description(s)\n","                del loss\n","                del det_loss\n","                del res_loss\n","                del outputs\n","\n","\n","\n","            scheduler.step()\n","            if args['local_rank'] == 0:\n","                # mAP\n","                last = test(args, ema.ema,criterion,weight_opt)\n","                writer.writerow({'mAP': str(f'{last[1]:.3f}'),\n","                                 'epoch': str(epoch + 1).zfill(3),\n","                                 'mAP@50': str(f'{last[0]:.3f}'),\n","                                  'PSNR': str(f'{last[2]:.3f}'),\n","                                  'SSIM': str(f'{last[3]:.3f}'),\n","                                 'total_loss': str(f'{m_loss.avg:.3f}'),\n","                                 'det_loss': str(f'{d_loss.avg:.3f}'),\n","                                 'res_loss': str(f'{r_loss.avg:.3f}'),\n","                                 'val_loss': str(f'{last[4]:.3f}'),\n","                                 'val_det': str(f'{last[5]:.3f}'),\n","                                 'val_res': str(f'{last[6]:.3f}'),\n","                                })\n","                f.flush()\n","\n","                # Update best mAP\n","                if last[0] > best:\n","                    best = last[0]\n","\n","                # Save model\n","                ckpt = {\n","                    'model': copy.deepcopy(model.module).half(),\n","                    'optimizer': optimizer.state_dict(),\n","                    'amp_scale': amp_scale.state_dict(),\n","                    'epoch': epoch,\n","                    'best': best,\n","                    'ema': copy.deepcopy(ema.ema).half(),  # Save EMA state\n","                    'ema_updates': ema.updates,  # Save updates\n","                    'scheduler': scheduler.state_dict(),  # Save scheduler state\n","\n","                }\n","                # Save last, best and delete\n","                torch.save(ckpt, 'last.pt')\n","                if best == last[0]:\n","                    torch.save(ckpt, 'best.pt')\n","                del ckpt\n","\n","    if args['local_rank'] == 0:\n","        strip_optimizer('best.pt')  # strip optimizers\n","        strip_optimizer('last.pt')  # strip optimizers\n","\n","    torch.cuda.empty_cache()\n","\n","\n","\n","@torch.no_grad()\n","def test(args, model=None,criterion=None,weight_opt=None):\n","    val_dir = '/kaggle/input/vocfog/vocfog/test'\n","    val_data = YOLODataset(val_dir, args['input_size'], args, False)\n","\n","    val_loader = DataLoader(val_data, batch_size=args['batch_size'], num_workers=4, shuffle=True,collate_fn=collateFunction)\n","\n","    if model is None:\n","        model = torch.load('/kaggle/input/weights/best (1).pt', map_location='cuda')['ema'].float()\n","\n","    if criterion is None:\n","        criterion = ComputeLoss(model, args)\n","\n","    model.half()\n","    model.eval()\n","\n","    # Configure\n","    iou_v = torch.linspace(0.5, 0.95, 10).cuda()  # iou vector for mAP@0.5:0.95\n","    n_iou = iou_v.numel()\n","    psnr_total = 0.\n","    ssim_total = 0.\n","    num_samples = 0\n","    m_pre = 0.\n","    m_rec = 0.\n","    map50 = 0.\n","    mean_ap = 0.\n","    metrics = []\n","    m_loss = AverageMeter()\n","    r_loss = AverageMeter()\n","    d_loss = AverageMeter()\n","\n","    p_bar = tqdm.tqdm(val_loader, desc=('%10s' * 3) % ('precision', 'recall', 'mAP'))\n","    for samples,norain, targets,shapes in p_bar:\n","        samples = samples.cuda()\n","        targets = targets.cuda()\n","        norain = norain.cuda()\n","        samples = samples.half()  # uint8 to fp16/32\n","        _, _, height, width = samples.shape  # batch size, channels, height, width\n","        pad_w, pad_h = shapes[0][1][1]\n","        pad_w, pad_h = int(pad_w), int(pad_h)\n","        # Inference\n","        outputs = model(samples)\n","        det_loss = criterion(outputs['Detection'][0], targets)\n","        res_loss = F.l1_loss(outputs['Restoration'], norain)\n","\n","        loss = (args['det'] * det_loss) + (args['res'] * res_loss)\n","\n","\n","\n","        m_loss.update(loss.item(), samples.size(0))\n","        d_loss.update(det_loss.item(), samples.size(0))\n","        r_loss.update(res_loss.item(), samples.size(0))\n","\n","\n","\n","        restoration = outputs['Restoration']\n","\n","        for i in range(samples.shape[0]):\n","            pad_h, pad_w = shapes[i][1][1]\n","            pad_h, pad_w = int(pad_h), int(pad_w)\n","\n","            # Apply padding to each image individually\n","            restored_img = restoration[i, :, pad_h:height-pad_h, pad_w:width-pad_w]\n","            norain_img = norain[i, :, pad_h:height-pad_h, pad_w:width-pad_w]\n","\n","            # Clamp and convert to byte for each image individually\n","            restored_img = torch.clamp(restored_img.mul(255), 0, 255).byte()\n","            norain_img = torch.clamp(norain_img.mul(255), 0, 255).byte()\n","            restored_img = restored_img.unsqueeze(0)\n","            norain_img = norain_img.unsqueeze(0)\n","            # Calculate PSNR and SSIM for each pair of images\n","            psnr_total += psnr(norain_img, restored_img)\n","            ssim_total += ssim(norain_img, restored_img)\n","            num_samples += 1\n","\n","        targets[:, 2:] *= torch.tensor((width, height, width, height)).cuda()  # to pixels\n","        det_outputs = non_max_suppression(outputs['Detection'][1], 0.001, 0.65)\n","        # Metrics\n","        for i, output in enumerate(det_outputs):\n","\n","            labels = targets[targets[:, 0] == i, 1:]\n","            correct = torch.zeros(output.shape[0], n_iou, dtype=torch.bool).cuda()\n","            if output.shape[0] == 0:\n","                if labels.shape[0]:\n","                    metrics.append((correct, *torch.zeros((3, 0)).cuda()))\n","                continue\n","\n","            detections = output.clone()\n","            scale(detections[:, :4], samples[i].shape[1:], shapes[i][0], shapes[i][1])\n","            # Evaluate\n","            if labels.shape[0]:\n","                tbox = labels[:, 1:5].clone()  # target boxes\n","                tbox[:, 0] = labels[:, 1] - labels[:, 3] / 2  # top left x\n","                tbox[:, 1] = labels[:, 2] - labels[:, 4] / 2  # top left y\n","                tbox[:, 2] = labels[:, 1] + labels[:, 3] / 2  # bottom right x\n","                tbox[:, 3] = labels[:, 2] + labels[:, 4] / 2  # bottom right y\n","                scale(tbox, samples[i].shape[1:], shapes[i][0], shapes[i][1])\n","\n","                correct = np.zeros((detections.shape[0], iou_v.shape[0]))\n","                correct = correct.astype(bool)\n","\n","                t_tensor = torch.cat((labels[:, 0:1], tbox), 1)\n","                iou = box_iou(t_tensor[:, 1:], detections[:, :4])\n","                correct_class = t_tensor[:, 0:1] == detections[:, 5]\n","                for j in range(len(iou_v)):\n","                    x = torch.where((iou >= iou_v[j]) & correct_class)\n","                    if x[0].shape[0]:\n","                        matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1)\n","                        matches = matches.cpu().numpy()\n","                        if x[0].shape[0] > 1:\n","                            matches = matches[matches[:, 2].argsort()[::-1]]\n","                            matches = matches[np.unique(matches[:, 1], return_index=True)[1]]\n","                            matches = matches[np.unique(matches[:, 0], return_index=True)[1]]\n","                        correct[matches[:, 1].astype(int), j] = True\n","                correct = torch.tensor(correct, dtype=torch.bool, device=iou_v.device)\n","\n","            metrics.append((correct, output[:, 4], output[:, 5], labels[:, 0]))\n","\n","    # Compute metrics\n","    metrics = [torch.cat(x, 0).cpu().numpy() for x in zip(*metrics)]  # to numpy\n","    if len(metrics) and metrics[0].any():\n","        tp, fp, m_pre, m_rec, map50, mean_ap = compute_ap(*metrics)\n","\n","    # Print results\n","    print('%10.4g' * 4 % (m_pre, m_rec, map50, mean_ap))\n","    avg_psnr = psnr_total / num_samples\n","    avg_ssim = ssim_total / num_samples\n","\n","    print('Average PSNR: %.4f' % avg_psnr)\n","    print('Average SSIM: %.4f' % avg_ssim)\n","    print('Val Det Loss: %.4f' % d_loss.avg)\n","    # Return results\n","    model.float()  # for training\n","    return map50, mean_ap, avg_psnr, avg_ssim, m_loss.avg,d_loss.avg,r_loss.avg\n","\n","\n","def main():\n","    args ={\n","        'input_size':640,\n","        'batch_size':16,\n","        'local_rank':0,\n","        'epochs': 100,\n","        'cosine_epochs':100,\n","        'world_size': 1,\n","        'lr0':1e-4,\n","        'lr1':1e-2,\n","        'lr2':1e-4,\n","        'lrf':1e-2,\n","        'lrf2':1e-2,\n","        'weight_decay':5e-4,\n","        'warmup_bias_lr':0,\n","        'Freeze_Epoch':0,\n","        'Freeze_Train': False,\n","        'warmup_epochs': 7,\n","        'warmup_momentum': 0.8,\n","        'momentum':0.93700000,\n","        'nc':5,\n","        'box': 7.5 ,                     # box loss gain\n","        'cls': 0.5,                      # cls loss gain\n","        'dfl': 1.5 ,\n","        'hsv_h': 0.015000,               # image HSV-Hue augmentation (fraction)\n","        'hsv_s': 0.700000,              # image HSV-Saturation augmentation (fraction)\n","        'hsv_v': 0.400000,               # image HSV-Value augmentation (fraction)\n","        'degrees': 0.0000,               # image rotation (+/- deg)\n","        'translate': 0.10,               # image translation (+/- fraction)\n","        'scale': 0.500000,               # image scale (+/- gain)\n","        'shear': 0.000000,               # image shear (+/- deg)\n","        'flip_ud': 0.0000,               # image flip up-down (probability)\n","        'flip_lr': 0.5000,               # image flip left-right (probability)\n","        'mosaic': 0.00000,               # image mosaic (probability)\n","        'mix_up': 0.00000,               # image mix-up (probability)\n","        'det': 0.6,\n","        'res': 0.4\n","    }\n","\n","    setup_seed()\n","    setup_multi_processes()\n","\n","\n","\n","    train(args)\n","#     test(args, params)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-21T00:54:32.729616Z","iopub.status.busy":"2024-06-21T00:54:32.729331Z"},"id":"qam5qIOjTVZ1","outputId":"39d5780f-4620-464a-c695-19eedf2862c8","papermill":{"duration":35862.035168,"end_time":"2024-02-26T00:24:34.085362","exception":false,"start_time":"2024-02-25T14:26:52.050194","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/utilis2/yolov8_s.pt'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[14], line 478\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    473\u001b[0m setup_seed()\n\u001b[0;32m    474\u001b[0m setup_multi_processes()\n\u001b[1;32m--> 478\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[14], line 48\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     46\u001b[0m device          \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     47\u001b[0m model_dict      \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstate_dict()\n\u001b[1;32m---> 48\u001b[0m pretrained_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/utilis2/yolov8_s.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(pretrained_dict\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m     50\u001b[0m pretrained_dict \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m pretrained_dict\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mshape(model_dict[k]) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mshape(v)}\n","File \u001b[1;32mc:\\Users\\zheng\\.conda\\envs\\py38\\lib\\site-packages\\torch\\serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n","File \u001b[1;32mc:\\Users\\zheng\\.conda\\envs\\py38\\lib\\site-packages\\torch\\serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n","File \u001b[1;32mc:\\Users\\zheng\\.conda\\envs\\py38\\lib\\site-packages\\torch\\serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/utilis2/yolov8_s.pt'"]}],"source":["main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LjJmFIDpeu5g","papermill":{"duration":2.923955,"end_time":"2024-02-26T00:24:40.012387","exception":false,"start_time":"2024-02-26T00:24:37.088432","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# depth = [1, 2, 2]\n","# width = [3, 32, 64, 128, 256, 512]\n","# model = YOLO(width, depth, 5).cuda()\n","# for i,(k,v) in enumerate(model.named_parameters()):\n","#     print(f'{i}: {k}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_D3s_DTTeu5g","papermill":{"duration":2.930091,"end_time":"2024-02-26T00:24:45.959999","exception":false,"start_time":"2024-02-26T00:24:43.029908","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# # # Define the mean and std\n","# args ={\n","#     'input_size':640,\n","#     'batch_size':8,\n","#     'local_rank':0,\n","#     'epochs': 100,\n","#     'cosine_epochs':100,\n","#     'world_size': 1,\n","#     'lr0':1e-2,\n","#     'lr1':1e-2,\n","#     'lr2':1e-2,\n","#     'lrf':1e-2,\n","#     'lrf2':1e-2,\n","#     'weight_decay':5e-4,\n","#     'warmup_bias_lr':0,\n","#     'Freeze_Epoch':0,\n","#     'Freeze_Train': False,\n","#     'warmup_epochs': 3,\n","#     'warmup_momentum': 0.8,\n","#     'momentum':0.93700000,\n","#     'nc':5,\n","#     'box': 7.5 ,                     # box loss gain\n","#     'cls': 0.5,                      # cls loss gain\n","#     'dfl': 1.5 ,\n","#     'hsv_h': 1.000000,               # image HSV-Hue augmentation (fraction)\n","#     'hsv_s': 0.700000,              # image HSV-Saturation augmentation (fraction)\n","#     'hsv_v': 0.400000,               # image HSV-Value augmentation (fraction)\n","#     'degrees': 0.0000,               # image rotation (+/- deg)\n","#     'translate': 0.10,               # image translation (+/- fraction)\n","#     'scale': 0.500000,               # image scale (+/- gain)\n","#     'shear': 5.000000,               # image shear (+/- deg)\n","#     'flip_ud': 0.5000,               # image flip up-down (probability)\n","#     'flip_lr': 0.5000,               # image flip left-right (probability)\n","#     'mosaic': 0.00000,               # image mosaic (probability)\n","#     'mix_up': 0.00000,               # image mix-up (probability)\n","# }\n","# train_dir = '/kaggle/input/vocfog/vocfog/train'\n","    \n","\n","# train_data = YOLODataset(train_dir, 512, args, True)\n","# train_loader = DataLoader(train_data, batch_size=1, num_workers=4,\n","#                                shuffle=True,collate_fn=collateFunction)\n","\n","# for i, (rainy_images, clean_images, targets,shapes) in enumerate(train_loader):\n","#     print(f'Train batch {i+1}:')\n","#     print(f'Rainy images shape: {rainy_images.shape}')\n","#     _, _, height, width = rainy_images.shape\n","#     # Denormalize the first image in the batch\n","#     pad_w, pad_h = shapes[0][1][1]\n","#     pad_w, pad_h = int(pad_w), int(pad_h)\n","#     nh=shapes[0][0][0] * shapes[0][1][0][0]\n","#     nw=shapes[0][0][1]*shapes[0][1][0][1]\n","#     # Display the first image in the batch\n","#     targets[:, 2:] *= torch.tensor((width, height, width, height)) # to pixels\n","#     labels = targets[targets[:, 0] == 0, 1:]\n","#     tbox = labels[:, 1:5].clone()  # target boxes\n","#     tbox[:, 0] = labels[:, 1] - labels[:, 3] / 2  # top left x\n","#     tbox[:, 1] = labels[:, 2] - labels[:, 4] / 2  # top left y\n","#     tbox[:, 2] = labels[:, 1] + labels[:, 3] / 2  # bottom right x\n","#     tbox[:, 3] = labels[:, 2] + labels[:, 4] / 2  # bottom right y\n","#     scale(tbox, (height,width), (nh,nw))\n","#     fig, ax = plt.subplots(1,2, figsize=(16,8))\n","\n","#     rainy_image = rainy_images[0][:, pad_h:height-pad_h, pad_w:width-pad_w]\n","#     ax[0].imshow(rainy_image.permute(1, 2, 0).clamp(0, 1))\n","\n","#     for box in tbox:\n","#         rect = patches.Rectangle((box[0], box[3]), box[2]-box[0], box[1]-box[3], linewidth=1, edgecolor='r', facecolor='none')\n","#         ax[0].add_patch(rect)\n","\n","#     clean_image = clean_images[0][:, pad_h:height-pad_h, pad_w:width-pad_w]\n","#     ax[1].imshow(clean_image.permute(1, 2, 0).clamp(0, 1))\n","\n","#     for box in tbox:\n","#         rect = patches.Rectangle((box[0], box[3]), box[2]-box[0], box[1]-box[3], linewidth=1, edgecolor='r', facecolor='none')\n","#         ax[1].add_patch(rect)\n","#     plt.tight_layout()\n","\n","#     plt.show()\n","# #     rainy_image = rainy_images[1] * std + mean\n","# #     print(annotations)\n","# #     # Display the first image in the batch\n","# #     fig, ax = plt.subplots(1)\n","# #     ax.imshow(rainy_image.permute(1, 2, 0).clamp(0, 1))\n","\n","#     # Draw the bounding boxes\n","# #     for box in annotations:\n","# #         box = box[2:]\n","# #         rect = patches.Rectangle(((box[0]-box[2]/2)*512, (box[1]-box[3]/2)*512), box[2]*512, box[3]*512, linewidth=1, edgecolor='r', facecolor='none')\n","# #         ax.add_patch(rect)\n","\n","# #     plt.show()\n","\n","#     if i == 3:  # Stop after 2 batches\n","#         break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"kbnew latest c4ad92","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4290880,"sourceId":7382950,"sourceType":"datasetVersion"},{"datasetId":4298594,"sourceId":7413305,"sourceType":"datasetVersion"},{"datasetId":4393707,"sourceId":7544783,"sourceType":"datasetVersion"},{"datasetId":4451076,"sourceId":7643646,"sourceType":"datasetVersion"},{"datasetId":4742404,"sourceId":8043341,"sourceType":"datasetVersion"},{"datasetId":4289538,"sourceId":8061874,"sourceType":"datasetVersion"},{"datasetId":5248799,"sourceId":8764251,"sourceType":"datasetVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"},"papermill":{"default_parameters":{},"duration":35928.826457,"end_time":"2024-02-26T00:24:57.752561","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-25T14:26:08.926104","version":"2.4.0"}},"nbformat":4,"nbformat_minor":4}
