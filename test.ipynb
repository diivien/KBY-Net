{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from model.kbynet import YOLO\n",
    "from model.metrics import AverageMeter, ComputeLoss, psnr,ssim\n",
    "from model.dataset import YOLODataset, collateFunction\n",
    "from model.utils import scale,box_iou,non_max_suppression, compute_ap_per_class\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def setup_seed():\n",
    "    \"\"\"\n",
    "    Setup random seed.\n",
    "    \"\"\"\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def setup_multi_processes():\n",
    "    \"\"\"\n",
    "    Setup multi-processing environment variables.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    from os import environ\n",
    "    from platform import system\n",
    "\n",
    "    # set multiprocess start method as `fork` to speed up the training\n",
    "    if system() != 'Windows':\n",
    "        torch.multiprocessing.set_start_method('fork', force=True)\n",
    "\n",
    "    # disable opencv multithreading to avoid system being overloaded\n",
    "    cv2.setNumThreads(0)\n",
    "\n",
    "    # setup OMP threads\n",
    "    if 'OMP_NUM_THREADS' not in environ:\n",
    "        environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "    # setup MKL threads\n",
    "    if 'MKL_NUM_THREADS' not in environ:\n",
    "        environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference(args, model=None):\n",
    "    val_dir = '/kaggle/input/citydata/citydata/test'\n",
    "    val_data = YOLODataset(val_dir, args['input_size'], args, False)\n",
    "    val_loader = DataLoader(val_data, batch_size=1, num_workers=4, shuffle=False,collate_fn=collateFunction)\n",
    "    if model is None:\n",
    "        model = torch.load('/kaggle/input/cleanweights/adamw.pt', map_location='cuda')['model'].float()\n",
    "    model.half()\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    class_names = ['person' , 'car', 'bicycle', 'motorcycle', 'bus']\n",
    "    p_bar = tqdm.tqdm(val_loader)\n",
    "    colors = ['r', 'g', 'b', 'y', 'm','c']\n",
    "    img_no = 0\n",
    "    for samples,norain, targets,shapes in p_bar:\n",
    "        samples = samples.cuda()\n",
    "        targets = targets.cuda()\n",
    "        samples = samples.half()  # uint8 to fp16/32\n",
    "        _, _, height, width = samples.shape  # batch size, channels, height, width\n",
    "        pad_w, pad_h = shapes[0][1][1]\n",
    "        pad_w, pad_h = int(pad_w), int(pad_h)\n",
    "        # Inference\n",
    "        nh=shapes[0][0][0] * shapes[0][1][0][0]\n",
    "        nw=shapes[0][0][1]*shapes[0][1][0][1]\n",
    "        outputs = model(samples)\n",
    "        restoration = outputs['Restoration'].float().cpu().numpy()\n",
    "        norain = norain.float().cpu().numpy()\n",
    "        # NMS\n",
    "        targets[:, 2:] *= torch.tensor((width, height, width, height)).cuda()  # to pixels\n",
    "        det_outputs = non_max_suppression(outputs['Detection'][1], 0.5, 0.7)\n",
    "\n",
    "        for i, output in enumerate(det_outputs):\n",
    "            plt.figure(figsize=(12, 8))  # Adjust figure size as needed\n",
    "\n",
    "\n",
    "            res_img = restoration[i][:, pad_h:height-pad_h, pad_w:width-pad_w]\n",
    "            plt.imshow(res_img.transpose((1,2,0)))\n",
    "\n",
    "\n",
    "            detections = output.clone()\n",
    "            scale(detections[:, :4], samples[i].shape[1:], (nh,nw))\n",
    "\n",
    "            if output.shape[0] > 0:\n",
    "                for box in detections.cpu().numpy():\n",
    "                    x1, y1, x2, y2, class_conf, class_pred = box\n",
    "                        # Use the class prediction to select a color\n",
    "                    if class_pred < 6:\n",
    "                        color = colors[int(class_pred) % len(colors)]\n",
    "                        bbox = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1, edgecolor=color, facecolor='none')\n",
    "                        plt.gca().add_patch(bbox)\n",
    "                        plt.text(x1, y1, s=class_names[int(class_pred)], color='white', verticalalignment='bottom',\n",
    "                                    bbox={'color': color, 'pad': 0}, fontsize=8)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.axis('off')  # Turn off axis display\n",
    "            plt.subplots_adjust(0, 0, 1, 1, 0, 0)  # Remove extra space around the image\n",
    "            plt.savefig(f'./kitti/{img_no}.png',bbox_inches='tight')  # Save the restoration image\n",
    "            # plt.show()\n",
    "            img_no+=1\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_per_class(args, model=None,criterion=None,weight_opt=None):\n",
    "    val_dir = '/kaggle/input/rain-kitti/rain_kitti_split/test'\n",
    "\n",
    "    val_data = YOLODataset(val_dir, args['input_size'], args, False)\n",
    "\n",
    "    val_loader = DataLoader(val_data, batch_size=args['batch_size'], num_workers=4, shuffle=True,collate_fn=collateFunction)\n",
    "\n",
    "    if model is None:\n",
    "        model = torch.load('/kaggle/input/cleanweights/6-4.pt', map_location='cuda')['model'].float()\n",
    "\n",
    "    if criterion is None:\n",
    "        criterion = ComputeLoss(model, args)\n",
    "\n",
    "    model.half()\n",
    "    model.eval()\n",
    "    class_mapping = {\n",
    "        0:\"person\",\n",
    "        1:\"car\",\n",
    "        2:\"bicycle\",\n",
    "        3:\"motorcycle\",\n",
    "        4:\"bus\"\n",
    "    }\n",
    "\n",
    "    # Configure\n",
    "    iou_v = torch.linspace(0.5, 0.95, 10).cuda()  # iou vector for mAP@0.5:0.95\n",
    "    n_iou = iou_v.numel()\n",
    "    psnr_total = 0.\n",
    "    ssim_total = 0.\n",
    "    num_samples = 0\n",
    "\n",
    "    metrics = []\n",
    "    m_loss = AverageMeter()\n",
    "    r_loss = AverageMeter()\n",
    "    d_loss = AverageMeter()\n",
    "\n",
    "    p_bar = tqdm.tqdm(val_loader, desc=('%10s' * 3) % ('precision', 'recall', 'mAP'))\n",
    "    for samples,norain, targets,shapes in p_bar:\n",
    "        samples = samples.cuda()\n",
    "        targets = targets.cuda()\n",
    "        norain = norain.cuda()\n",
    "        samples = samples.half()  # uint8 to fp16/32\n",
    "        _, _, height, width = samples.shape  # batch size, channels, height, width\n",
    "        pad_w, pad_h = shapes[0][1][1]\n",
    "        pad_w, pad_h = int(pad_w), int(pad_h)\n",
    "        # Inference\n",
    "        outputs = model(samples)\n",
    "        det_loss = criterion(outputs['Detection'][0], targets)\n",
    "        res_loss = F.l1_loss(outputs['Restoration'], norain)\n",
    "\n",
    "        loss = (args['det'] * det_loss) + (args['res'] * res_loss)\n",
    "\n",
    "\n",
    "        m_loss.update(loss.item(), samples.size(0))\n",
    "        d_loss.update(det_loss.item(), samples.size(0))\n",
    "        r_loss.update(res_loss.item(), samples.size(0))\n",
    "\n",
    "\n",
    "\n",
    "        restoration = outputs['Restoration']\n",
    "\n",
    "        for i in range(samples.shape[0]):\n",
    "            pad_h, pad_w = shapes[i][1][1]\n",
    "            pad_h, pad_w = int(pad_h), int(pad_w)\n",
    "\n",
    "            # Apply padding to each image individually\n",
    "            restored_img = restoration[i, :, pad_h:height-pad_h, pad_w:width-pad_w]\n",
    "            norain_img = norain[i, :, pad_h:height-pad_h, pad_w:width-pad_w]\n",
    "\n",
    "            # Clamp and convert to byte for each image individually\n",
    "            restored_img = torch.clamp(restored_img.mul(255), 0, 255).byte()\n",
    "            norain_img = torch.clamp(norain_img.mul(255), 0, 255).byte()\n",
    "            restored_img = restored_img.unsqueeze(0)\n",
    "            norain_img = norain_img.unsqueeze(0)\n",
    "            # Calculate PSNR and SSIM for each pair of images\n",
    "            psnr_total += psnr(norain_img, restored_img)\n",
    "            ssim_total += ssim(norain_img, restored_img)\n",
    "            num_samples += 1\n",
    "\n",
    "        targets[:, 2:] *= torch.tensor((width, height, width, height)).cuda()  # to pixels\n",
    "        det_outputs = non_max_suppression(outputs['Detection'][1], 0.001, 0.65)\n",
    "        # Metrics\n",
    "        for i, output in enumerate(det_outputs):\n",
    "\n",
    "            labels = targets[targets[:, 0] == i, 1:]\n",
    "            correct = torch.zeros(output.shape[0], n_iou, dtype=torch.bool).cuda()\n",
    "            if output.shape[0] == 0:\n",
    "                if labels.shape[0]:\n",
    "                    metrics.append((correct, *torch.zeros((3, 0)).cuda()))\n",
    "                continue\n",
    "\n",
    "            detections = output.clone()\n",
    "            scale(detections[:, :4], samples[i].shape[1:], shapes[i][0], shapes[i][1])\n",
    "            # Evaluate\n",
    "            if labels.shape[0]:\n",
    "                tbox = labels[:, 1:5].clone()  # target boxes\n",
    "                tbox[:, 0] = labels[:, 1] - labels[:, 3] / 2  # top left x\n",
    "                tbox[:, 1] = labels[:, 2] - labels[:, 4] / 2  # top left y\n",
    "                tbox[:, 2] = labels[:, 1] + labels[:, 3] / 2  # bottom right x\n",
    "                tbox[:, 3] = labels[:, 2] + labels[:, 4] / 2  # bottom right y\n",
    "                scale(tbox, samples[i].shape[1:], shapes[i][0], shapes[i][1])\n",
    "\n",
    "                correct = np.zeros((detections.shape[0], iou_v.shape[0]))\n",
    "                correct = correct.astype(bool)\n",
    "\n",
    "                t_tensor = torch.cat((labels[:, 0:1], tbox), 1)\n",
    "                iou = box_iou(t_tensor[:, 1:], detections[:, :4])\n",
    "                correct_class = t_tensor[:, 0:1] == detections[:, 5]\n",
    "                for j in range(len(iou_v)):\n",
    "                    x = torch.where((iou >= iou_v[j]) & correct_class)\n",
    "                    if x[0].shape[0]:\n",
    "                        matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1)\n",
    "                        matches = matches.cpu().numpy()\n",
    "                        if x[0].shape[0] > 1:\n",
    "                            matches = matches[matches[:, 2].argsort()[::-1]]\n",
    "                            matches = matches[np.unique(matches[:, 1], return_index=True)[1]]\n",
    "                            matches = matches[np.unique(matches[:, 0], return_index=True)[1]]\n",
    "                        correct[matches[:, 1].astype(int), j] = True\n",
    "                correct = torch.tensor(correct, dtype=torch.bool, device=iou_v.device)\n",
    "\n",
    "            metrics.append((correct, output[:, 4], output[:, 5], labels[:, 0]))\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics = [torch.cat(x, 0).cpu().numpy() for x in zip(*metrics)]  # to numpy\n",
    "    if len(metrics) and metrics[0].any():\n",
    "        ap50_per_class = compute_ap_per_class(*metrics,args['nc'])\n",
    "    for i in range(args['nc']):\n",
    "        print(f\"AP@0.5 for class {class_mapping[i]}: {ap50_per_class[i]:.4f}\")\n",
    "    # Calculate the overall mAP@0.5\n",
    "    overall_map50 = np.mean(ap50_per_class)\n",
    "\n",
    "    # Print the overall mAP@0.5\n",
    "    print(f\"Overall mAP@0.5: {overall_map50}\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(args, model=None,criterion=None,weight_opt=None):\n",
    "    val_dir = '/kaggle/input/vocfog/vocfog/test'\n",
    "    val_data = YOLODataset(val_dir, args['input_size'], args, False)\n",
    "\n",
    "    val_loader = DataLoader(val_data, batch_size=args['batch_size'], num_workers=4, shuffle=True,collate_fn=collateFunction)\n",
    "\n",
    "    if model is None:\n",
    "        model = torch.load('/kaggle/input/weights/best (1).pt', map_location='cuda')['ema'].float()\n",
    "\n",
    "    if criterion is None:\n",
    "        criterion = ComputeLoss(model, args)\n",
    "\n",
    "    model.half()\n",
    "    model.eval()\n",
    "\n",
    "    # Configure\n",
    "    iou_v = torch.linspace(0.5, 0.95, 10).cuda()  # iou vector for mAP@0.5:0.95\n",
    "    n_iou = iou_v.numel()\n",
    "    psnr_total = 0.\n",
    "    ssim_total = 0.\n",
    "    num_samples = 0\n",
    "    m_pre = 0.\n",
    "    m_rec = 0.\n",
    "    map50 = 0.\n",
    "    mean_ap = 0.\n",
    "    metrics = []\n",
    "    m_loss = AverageMeter()\n",
    "    r_loss = AverageMeter()\n",
    "    d_loss = AverageMeter()\n",
    "\n",
    "    p_bar = tqdm.tqdm(val_loader, desc=('%10s' * 3) % ('precision', 'recall', 'mAP'))\n",
    "    for samples,norain, targets,shapes in p_bar:\n",
    "        samples = samples.cuda()\n",
    "        targets = targets.cuda()\n",
    "        norain = norain.cuda()\n",
    "        samples = samples.half()  # uint8 to fp16/32\n",
    "        _, _, height, width = samples.shape  # batch size, channels, height, width\n",
    "        pad_w, pad_h = shapes[0][1][1]\n",
    "        pad_w, pad_h = int(pad_w), int(pad_h)\n",
    "        # Inference\n",
    "        outputs = model(samples)\n",
    "        det_loss = criterion(outputs['Detection'][0], targets)\n",
    "        res_loss = F.l1_loss(outputs['Restoration'], norain)\n",
    "\n",
    "        loss = (args['det'] * det_loss) + (args['res'] * res_loss)\n",
    "\n",
    "\n",
    "\n",
    "        m_loss.update(loss.item(), samples.size(0))\n",
    "        d_loss.update(det_loss.item(), samples.size(0))\n",
    "        r_loss.update(res_loss.item(), samples.size(0))\n",
    "\n",
    "\n",
    "\n",
    "        restoration = outputs['Restoration']\n",
    "\n",
    "        for i in range(samples.shape[0]):\n",
    "            pad_h, pad_w = shapes[i][1][1]\n",
    "            pad_h, pad_w = int(pad_h), int(pad_w)\n",
    "\n",
    "            # Apply padding to each image individually\n",
    "            restored_img = restoration[i, :, pad_h:height-pad_h, pad_w:width-pad_w]\n",
    "            norain_img = norain[i, :, pad_h:height-pad_h, pad_w:width-pad_w]\n",
    "\n",
    "            # Clamp and convert to byte for each image individually\n",
    "            restored_img = torch.clamp(restored_img.mul(255), 0, 255).byte()\n",
    "            norain_img = torch.clamp(norain_img.mul(255), 0, 255).byte()\n",
    "            restored_img = restored_img.unsqueeze(0)\n",
    "            norain_img = norain_img.unsqueeze(0)\n",
    "            # Calculate PSNR and SSIM for each pair of images\n",
    "            psnr_total += psnr(norain_img, restored_img)\n",
    "            ssim_total += ssim(norain_img, restored_img)\n",
    "            num_samples += 1\n",
    "\n",
    "        targets[:, 2:] *= torch.tensor((width, height, width, height)).cuda()  # to pixels\n",
    "        det_outputs = non_max_suppression(outputs['Detection'][1], 0.001, 0.65)\n",
    "        # Metrics\n",
    "        for i, output in enumerate(det_outputs):\n",
    "\n",
    "            labels = targets[targets[:, 0] == i, 1:]\n",
    "            correct = torch.zeros(output.shape[0], n_iou, dtype=torch.bool).cuda()\n",
    "            if output.shape[0] == 0:\n",
    "                if labels.shape[0]:\n",
    "                    metrics.append((correct, *torch.zeros((3, 0)).cuda()))\n",
    "                continue\n",
    "\n",
    "            detections = output.clone()\n",
    "            scale(detections[:, :4], samples[i].shape[1:], shapes[i][0], shapes[i][1])\n",
    "            # Evaluate\n",
    "            if labels.shape[0]:\n",
    "                tbox = labels[:, 1:5].clone()  # target boxes\n",
    "                tbox[:, 0] = labels[:, 1] - labels[:, 3] / 2  # top left x\n",
    "                tbox[:, 1] = labels[:, 2] - labels[:, 4] / 2  # top left y\n",
    "                tbox[:, 2] = labels[:, 1] + labels[:, 3] / 2  # bottom right x\n",
    "                tbox[:, 3] = labels[:, 2] + labels[:, 4] / 2  # bottom right y\n",
    "                scale(tbox, samples[i].shape[1:], shapes[i][0], shapes[i][1])\n",
    "\n",
    "                correct = np.zeros((detections.shape[0], iou_v.shape[0]))\n",
    "                correct = correct.astype(bool)\n",
    "\n",
    "                t_tensor = torch.cat((labels[:, 0:1], tbox), 1)\n",
    "                iou = box_iou(t_tensor[:, 1:], detections[:, :4])\n",
    "                correct_class = t_tensor[:, 0:1] == detections[:, 5]\n",
    "                for j in range(len(iou_v)):\n",
    "                    x = torch.where((iou >= iou_v[j]) & correct_class)\n",
    "                    if x[0].shape[0]:\n",
    "                        matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1)\n",
    "                        matches = matches.cpu().numpy()\n",
    "                        if x[0].shape[0] > 1:\n",
    "                            matches = matches[matches[:, 2].argsort()[::-1]]\n",
    "                            matches = matches[np.unique(matches[:, 1], return_index=True)[1]]\n",
    "                            matches = matches[np.unique(matches[:, 0], return_index=True)[1]]\n",
    "                        correct[matches[:, 1].astype(int), j] = True\n",
    "                correct = torch.tensor(correct, dtype=torch.bool, device=iou_v.device)\n",
    "\n",
    "            metrics.append((correct, output[:, 4], output[:, 5], labels[:, 0]))\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics = [torch.cat(x, 0).cpu().numpy() for x in zip(*metrics)]  # to numpy\n",
    "    if len(metrics) and metrics[0].any():\n",
    "        tp, fp, m_pre, m_rec, map50, mean_ap = compute_ap(*metrics)\n",
    "\n",
    "    # Print results\n",
    "    print('%10.4g' * 4 % (m_pre, m_rec, map50, mean_ap))\n",
    "    avg_psnr = psnr_total / num_samples\n",
    "    avg_ssim = ssim_total / num_samples\n",
    "\n",
    "    print('Average PSNR: %.4f' % avg_psnr)\n",
    "    print('Average SSIM: %.4f' % avg_ssim)\n",
    "    print('Val Det Loss: %.4f' % d_loss.avg)\n",
    "    # Return results\n",
    "    model.float()  # for training\n",
    "    return map50, mean_ap, avg_psnr, avg_ssim, m_loss.avg,d_loss.avg,r_loss.avg\n",
    "\n",
    "def main():\n",
    "    args ={\n",
    "        'input_size':640,\n",
    "        'batch_size':16,\n",
    "        'local_rank':0,\n",
    "        'epochs': 100,\n",
    "        'cosine_epochs':100,\n",
    "        'world_size': 1,\n",
    "        'lr0':1e-4,\n",
    "        'lr1':1e-2,\n",
    "        'lr2':1e-4,\n",
    "        'lrf':1e-2,\n",
    "        'lrf2':1e-2,\n",
    "        'weight_decay':5e-4,\n",
    "        'warmup_bias_lr':0,\n",
    "        'Freeze_Epoch':0,\n",
    "        'Freeze_Train': False,\n",
    "        'warmup_epochs': 7,\n",
    "        'warmup_momentum': 0.8,\n",
    "        'momentum':0.93700000,\n",
    "        'nc':5,\n",
    "        'box': 7.5 ,                     # box loss gain\n",
    "        'cls': 0.5,                      # cls loss gain\n",
    "        'dfl': 1.5 ,\n",
    "        'hsv_h': 0.015000,               # image HSV-Hue augmentation (fraction)\n",
    "        'hsv_s': 0.700000,              # image HSV-Saturation augmentation (fraction)\n",
    "        'hsv_v': 0.400000,               # image HSV-Value augmentation (fraction)\n",
    "        'degrees': 0.0000,               # image rotation (+/- deg)\n",
    "        'translate': 0.10,               # image translation (+/- fraction)\n",
    "        'scale': 0.500000,               # image scale (+/- gain)\n",
    "        'shear': 0.000000,               # image shear (+/- deg)\n",
    "        'flip_ud': 0.0000,               # image flip up-down (probability)\n",
    "        'flip_lr': 0.5000,               # image flip left-right (probability)\n",
    "        'mosaic': 0.00000,               # image mosaic (probability)\n",
    "        'mix_up': 0.00000,               # image mix-up (probability)\n",
    "        'det': 0.6,\n",
    "        'res': 0.4\n",
    "    }\n",
    "\n",
    "    setup_seed()\n",
    "    setup_multi_processes()\n",
    "#     with open('/kaggle/input/utilis2/argscity.yaml', errors='ignore') as f:\n",
    "#         params = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "    test(args)\n",
    "    # test_per_class(args)\n",
    "#     inference(args)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
